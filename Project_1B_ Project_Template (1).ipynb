{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages\n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/home\n",
      "['/workspace/home/event_data/2018-11-17-events.csv', '/workspace/home/event_data/2018-11-28-events.csv', '/workspace/home/event_data/2018-11-29-events.csv', '/workspace/home/event_data/2018-11-13-events.csv', '/workspace/home/event_data/2018-11-14-events.csv', '/workspace/home/event_data/2018-11-03-events.csv', '/workspace/home/event_data/2018-11-07-events.csv', '/workspace/home/event_data/2018-11-05-events.csv', '/workspace/home/event_data/2018-11-26-events.csv', '/workspace/home/event_data/2018-11-21-events.csv', '/workspace/home/event_data/2018-11-02-events.csv', '/workspace/home/event_data/2018-11-10-events.csv', '/workspace/home/event_data/2018-11-11-events.csv', '/workspace/home/event_data/2018-11-12-events.csv', '/workspace/home/event_data/2018-11-22-events.csv', '/workspace/home/event_data/2018-11-18-events.csv', '/workspace/home/event_data/2018-11-08-events.csv', '/workspace/home/event_data/2018-11-06-events.csv', '/workspace/home/event_data/2018-11-25-events.csv', '/workspace/home/event_data/2018-11-19-events.csv', '/workspace/home/event_data/2018-11-23-events.csv', '/workspace/home/event_data/2018-11-24-events.csv', '/workspace/home/event_data/2018-11-30-events.csv', '/workspace/home/event_data/2018-11-04-events.csv', '/workspace/home/event_data/2018-11-15-events.csv', '/workspace/home/event_data/2018-11-16-events.csv', '/workspace/home/event_data/2018-11-20-events.csv', '/workspace/home/event_data/2018-11-09-events.csv', '/workspace/home/event_data/2018-11-27-events.csv', '/workspace/home/event_data/2018-11-01-events.csv']\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    print(file_path_list) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8056\n",
      "\n",
      " ['Kenny G', 'Logged In', 'Chloe', 'F', '53', 'Cuevas', '256.57424', 'paid', 'San Francisco-Oakland-Hayward, CA', 'PUT', 'NextSong', '1.54094E+12', '648', 'Everlasting', '200', '1.54241E+12', '49'] \n",
      " ['Randy Crawford', 'Logged In', 'Chloe', 'F', '54', 'Cuevas', '251.402', 'paid', 'San Francisco-Oakland-Hayward, CA', 'PUT', 'NextSong', '1.54094E+12', '648', 'Rio De Janeiro Blue (Album Version)', '200', '1.54241E+12', '49']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    "# extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "print('\\n',full_data_rows_list[0],'\\n', full_data_rows_list[1])\n",
    "\n",
    "##########################\n",
    "# creating a smaller event data csv file called event_datafile_full csv \n",
    "# that will be used to insert data into the Apache Cassandra tables\n",
    "#########################\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================\n",
    "# Creating a Cluster\n",
    "#==================\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server: code=2200 [Invalid query] message=\"unconfigured table music_library\"\n"
     ]
    }
   ],
   "source": [
    "#Test the connection. Expecting error. \n",
    "\n",
    "try:\n",
    "    session.execute(\"\"\"select * from music_library \"\"\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================================================================\n",
    "# Create a Keyspace named p1_udacity with the SimpleStrategy replication strategy and a replication factor of 1\n",
    "#===============================================================================================================\n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS p1_udacity\n",
    "    WITH REPLICATION =\n",
    "    {'class' : 'SimpleStrategy', 'replication_factor': 1}\"\"\"\n",
    "                   )\n",
    "except Exception as e:\n",
    "\tprint (e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====================================================\n",
    "#Set the keyspace p1_udacity for the Cassandra session\n",
    "#=====================================================\n",
    "try:\n",
    "    session.set_keyspace('p1_udacity')\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create queries to ask the following three questions of the data\n",
    "\n",
    "1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file will be used in 3 queries\n",
    "file = 'event_datafile_new.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### For building the ETL Pipeline to address each of these questions above, there are concrete 3 steps that we would follow: \n",
    "+ Creating each table for each question using CREATE statement \n",
    "+ Loading the data into the newly created table using the INSERT INTO statement\n",
    "+ Validate the data using SELECT FROM WHERE clause to retrieve the specific columns from a table with relevant conditions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### QUERY 1: Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "For this query we pick the *table song_features*, \n",
    "+ Collumn **itemInSession** is used as a partition key because the queries will filter by this column. \n",
    "+ Collumn **sessionId** is used as clustering column to help make up a unique key.\n",
    "\n",
    "*The combination of these two columns will be used to uniquely identify rows in the table.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f3dd68ee5c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################\n",
    "# Create table:\n",
    "#################\n",
    "\n",
    "session.execute(\"DROP TABLE IF EXISTS song_features\")\n",
    "\n",
    "# create table for Query 1\n",
    "song_features = \"\"\"CREATE TABLE IF NOT EXISTS song_features (\n",
    "                                itemInSession int, \n",
    "                                sessionId int, \n",
    "                                artist text, \n",
    "                                song text,\n",
    "                                length float, \n",
    "                                PRIMARY KEY(itemInSession, sessionId) \n",
    "                                )\"\"\"\n",
    "\n",
    "\n",
    "# execute the newly created table \n",
    "session.execute(song_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Insert the data\n",
    "#################\n",
    "\n",
    "# insert data for song_features\n",
    "insert_data_song_features = \"\"\"INSERT INTO song_features (\n",
    "                                         itemInSession, \n",
    "                                         sessionId, \n",
    "                                         artist, \n",
    "                                         song, \n",
    "                                         length) \n",
    "                                VALUES (%s, %s, %s, %s, %s)\"\"\"\n",
    "\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        # adding columns from csv in each variable\n",
    "        itemInSession, sessionId, song, artist, length = int(line[3]), int(line[8]), str(line[9]), str(line[0]), float(line[5])\n",
    "        \n",
    "        # execute the insertion\n",
    "        session.execute (insert_data_song_features, (itemInSession, sessionId, song, artist, length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist: Faithless, song: Music Matters (Mark Knight Dub) length: 495.30731\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# Validate the data\n",
    "###################\n",
    "\n",
    "query_1 = \"\"\"SELECT artist, song, length \n",
    "                    FROM song_features \n",
    "                    WHERE itemInSession = %s AND sessionId = %s\"\"\"\n",
    "\n",
    "rows = session.execute(query_1, (4, 338)) #execute the query according to the question\n",
    "\n",
    "#print the value of them for each column artist, song, length\n",
    "for row in rows:\n",
    "    print(f'artist: {row.artist}, song: {row.song} length: {row.length:.8}')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182 \n",
    "\n",
    "For this query we pick the *artist_song_by_user*, \n",
    "+ the **userId** and **sessionId** are used as a composite partition key because the queries will filter by these columns.\n",
    "+ The **itemInSession** are used as clustering column to help make up a unique key.\n",
    "\n",
    "*The combination of these two columns will be used to uniquely identify rows in the table.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f3dd7191780>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#====================================================\n",
    "# Create table\n",
    "\n",
    "#====================================================\n",
    "\n",
    "# in case rerun this cell, drop the current table \n",
    "session.execute(\"DROP TABLE IF EXISTS artist_song_by_user\")\n",
    "\n",
    "# create table for Query 1\n",
    "artist_song_by_user = \"\"\"CREATE TABLE IF NOT EXISTS artist_song_by_user (\n",
    "                                                        userId int, \n",
    "                                                        sessionId int, \n",
    "                                                        itemInSession int, \n",
    "                                                        artist text, \n",
    "                                                        song text, \n",
    "                                                        firstName text, \n",
    "                                                        lastName text, \n",
    "                                                        PRIMARY KEY ((userId, sessionId), itemInSession)\n",
    "                                                        )\"\"\"\n",
    "# execute the create table\n",
    "session.execute(artist_song_by_user)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================== \n",
    "# Insert the data\n",
    "#==================\n",
    "\n",
    "insert_data_artist_song_by_user = \"\"\"INSERT INTO artist_song_by_user (\n",
    "                                                 userId, \n",
    "                                                 sessionId, \n",
    "                                                 itemInSession, \n",
    "                                                 artist, \n",
    "                                                 song, \n",
    "                                                 firstName, \n",
    "                                                 lastName) \n",
    "                                     VALUES (%s, %s, %s, %s, %s, %s, %s)\"\"\"\n",
    "\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        # adding columns from csv in each variable\n",
    "        userId, sessionId, itemInSession, song, artist, firstName, lastName  = int(line[10]), int(line[8]), int(line[3]), str(line[9]), \\\n",
    "                                                                                str(line[0]), str(line[1]), str(line[4])\n",
    "         \n",
    "        \n",
    "        # execute the insertion\n",
    "        session.execute(insert_data_artist_song_by_user, (userId, sessionId, itemInSession, song, artist, firstName, lastName))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist: Down To The Bone, song: Keep On Keepin' On, user first name: Sylvie, user last name: Cruz\n",
      "artist: Three Drives, song: Greece 2000, user first name: Sylvie, user last name: Cruz\n",
      "artist: Sebastien Tellier, song: Kilometer, user first name: Sylvie, user last name: Cruz\n",
      "artist: Lonnie Gordon, song: Catch You Baby (Steve Pitron & Max Sanna Radio Edit), user first name: Sylvie, user last name: Cruz\n"
     ]
    }
   ],
   "source": [
    "#==================\n",
    "# Validate the data\n",
    "#==================\n",
    "\n",
    "# Query 2 in CQL\n",
    "query_2 = \"\"\"SELECT artist, song, firstName, lastName \n",
    "                    FROM artist_song_by_user\n",
    "                    WHERE userId = %s AND sessionId = %s\"\"\"\n",
    "\n",
    "rows = session.execute(query_2, (10, 182))\n",
    "for row in rows:\n",
    "    print(f'artist: {row.artist}, song: {row.song}, user first name: {row.firstname}, user last name: {row.lastname}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### QUERY 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n",
    "For table *user_name*, \n",
    "+ the **song** was used as a partition key because the queries will filter by \n",
    "this column. \n",
    "+ The **userId** were used as clustering column to help make up a unique key.\n",
    "\n",
    "*The combination of these two columns will be used to uniquely identify rows in the table.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f3dd719b198>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#====================================================\n",
    "# Create table\n",
    "\n",
    "#====================================================\n",
    "\n",
    "# in case rerun this cell, drop the current table \n",
    "session.execute(\"DROP TABLE IF EXISTS table_query_3\")\n",
    "\n",
    "# create table for Query 1\n",
    "user_name = \"\"\"CREATE TABLE IF NOT EXISTS user_name (\n",
    "                                        song text, \n",
    "                                        userId int, \n",
    "                                        firstName text, \n",
    "                                        lastName text, \n",
    "                                        PRIMARY KEY (song, userId)\n",
    "                                        )\"\"\"\n",
    "# execute the create table\n",
    "session.execute(user_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================\n",
    "# Insert the data\n",
    "#==================\n",
    "\n",
    "insert_data_user_name = \"\"\"INSERT INTO user_name (\n",
    "                                            song, \n",
    "                                            userId, \n",
    "                                            firstName, \n",
    "                                            lastName\n",
    "                                            ) \n",
    "                                            VALUES (%s, %s, %s, %s)\"\"\"\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        # adding columns from csv in each variable\n",
    "        song, userId, firstName, lastName = str(line[9]), int(line[10]), str(line[1]), str(line[4])\n",
    "        \n",
    "        # execute the insertion\n",
    "        session.execute(insert_data_user_name, (song, userId, firstName, lastName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user first name: Jacqueline,  user last name: Lynch\n",
      "user first name:      Tegan,  user last name: Levine\n",
      "user first name:       Sara,  user last name: Johnson\n"
     ]
    }
   ],
   "source": [
    "#==================\n",
    "# Verify the data\n",
    "#==================\n",
    "\n",
    "# Query 3 in CQL\n",
    "query_3 = \"\"\"SELECT firstName, lastName \n",
    "                    FROM user_name \n",
    "                    WHERE song = %s\"\"\"\n",
    "                    \n",
    "#the name of the song now used as the query condition\n",
    "rows = session.execute(query_3, ('All Hands Against His Own', ))\n",
    "\n",
    "# print the user\n",
    "for row in rows:\n",
    "    print(f'user first name: {row.firstname:>10},  user last name: {row.lastname}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================\n",
    "# Drop the table before closing out the sessions\n",
    "#=================================================\n",
    "\n",
    "session.execute(\"DROP TABLE IF EXISTS song_features\")\n",
    "session.execute(\"DROP TABLE IF EXISTS artist_song_by_user\")\n",
    "session.execute(\"DROP TABLE IF EXISTS user_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINISH"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
